{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp5Nn7lzV3J6",
        "colab_type": "text"
      },
      "source": [
        "# Load pytorch library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZzTc_qcr0ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtysNYMHV-XR",
        "colab_type": "text"
      },
      "source": [
        "# Define validation dataset ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO2LXvudAog6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "valid_ratio = 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m77sHXmJWHfx",
        "colab_type": "text"
      },
      "source": [
        "# Define the MNIST training and validation sets, and possible transforms to be applied. Optional augmentation can be done within the transform. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNDByYIhr4TU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "    #  transforms.RandomRotation(degrees=30),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_valid_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "nb_train = int((1.0 - valid_ratio) * len(train_valid_dataset))\n",
        "nb_valid =  int(valid_ratio * len(train_valid_dataset))\n",
        "train_dataset, valid_dataset = torch.utils.data.dataset.random_split(train_valid_dataset, [nb_train, nb_valid])\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=500,\n",
        "                                          shuffle=True)\n",
        "validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=500,\n",
        "                                          shuffle=True)\n",
        "\n",
        "classes = ('0', '1', '2', '3',\n",
        "           '4', '5', '6', '7', '8', '9')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEynLBaxWrnQ",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO8X36thsFKF",
        "colab_type": "code",
        "outputId": "216d08d7-badf-43a1-ad0d-6120b3c2a63e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:4,]))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB5CAYAAAAtfwoEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "    8     6     8     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CUKf7kcW3Rh",
        "colab_type": "text"
      },
      "source": [
        "# Construct the CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOsjlBUKsbTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(-1, 32 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FC-AEZXXJE4",
        "colab_type": "text"
      },
      "source": [
        "# Instantiate the CNN and print out the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghak7OKCXXpK",
        "colab_type": "code",
        "outputId": "b151f9a0-4ba9-498c-db97-07d37855b549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net = Net()\n",
        "print(sum([p.numel() for p in net.parameters()]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "884330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slDGVTtkXd-Z",
        "colab_type": "text"
      },
      "source": [
        "# Define the loss function and the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml4xvTi7sgCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9WLDB1R0CnA",
        "colab_type": "text"
      },
      "source": [
        "# Select the device to train the CNN! \"cuda:0\" means the first GPU device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W90Lsx16swAe",
        "colab_type": "code",
        "outputId": "97e62b88-5500-4214-ddfd-6d4838522e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "net.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=1568, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La3a6S81YSWs",
        "colab_type": "text"
      },
      "source": [
        "# Mount your google drive to current virtual machine. And define the path to store the trained CNN parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwLWBzgOuYZW",
        "colab_type": "code",
        "outputId": "64620603-12c4-497a-e3ab-ece2f7a64269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH = 'drive/My Drive/ML19/mnist_net.pth'\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dLwz9XsYkNJ",
        "colab_type": "text"
      },
      "source": [
        "# Train the CNN and store the best model based on the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csCvcF7Ss1Ud",
        "colab_type": "code",
        "outputId": "83001a41-dbe7-4694-95bd-d4732fe9ed6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "best_loss = np.float('inf')\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "    epoch_loss = running_loss / (i+1)\n",
        "    print(\"Epoch: \", epoch, \" train loss: \", '%.3f' % epoch_loss)\n",
        "    with torch.no_grad(): \n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(validloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          # forward \n",
        "          outputs = net(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # print statistics\n",
        "          running_loss += loss.item()\n",
        "      epoch_loss = running_loss / (i+1)\n",
        "      print(\"Epoch: \", epoch, \" validation loss: \", '%.3f' % epoch_loss)\n",
        "      if epoch_loss < best_loss:\n",
        "        torch.save(net.state_dict(), PATH)\n",
        "        best_loss = epoch_loss\n",
        "\n",
        "time_elap = (time.time() - start_time) // 60\n",
        "print('Finished Training in %d mins' % time_elap)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0  train loss:  0.546\n",
            "Epoch:  0  validation loss:  0.106\n",
            "Epoch:  1  train loss:  0.086\n",
            "Epoch:  1  validation loss:  0.084\n",
            "Epoch:  2  train loss:  0.060\n",
            "Epoch:  2  validation loss:  0.068\n",
            "Epoch:  3  train loss:  0.046\n",
            "Epoch:  3  validation loss:  0.053\n",
            "Epoch:  4  train loss:  0.035\n",
            "Epoch:  4  validation loss:  0.062\n",
            "Epoch:  5  train loss:  0.035\n",
            "Epoch:  5  validation loss:  0.062\n",
            "Epoch:  6  train loss:  0.033\n",
            "Epoch:  6  validation loss:  0.057\n",
            "Epoch:  7  train loss:  0.029\n",
            "Epoch:  7  validation loss:  0.065\n",
            "Epoch:  8  train loss:  0.030\n",
            "Epoch:  8  validation loss:  0.075\n",
            "Epoch:  9  train loss:  0.025\n",
            "Epoch:  9  validation loss:  0.065\n",
            "Finished Training in 2 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfvPe-jSYsrR",
        "colab_type": "text"
      },
      "source": [
        "# Define the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQSOIHv7yf-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "     [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.1307,), (0.3081,))])\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nqrJcR2Yzs5",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqvrOr83y2B1",
        "colab_type": "code",
        "outputId": "605fb531-f82d-4e11-c85f-e87ffe630233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "    \n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB5CAYAAAAtfwoEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPXUlEQVR4nO3df6wV5Z3H8fdXRO2tCcjWoIKiRCKy\njRZyw0I0CmqzwjZF8EfU6mokuUa7WZFGewVkwwqRDUZdf5TmUlhBFBZB5IqyriLGNFoVQS2KVCxS\nMBehurZ2ifa6fvePmTOOcs49c37fmfN5JTf3OTPPnPk+Zy5fnvPMzDPm7oiISHYc1ugARESkupTY\nRUQyRoldRCRjlNhFRDJGiV1EJGOU2EVEMqaixG5mF5rZDjPbaWbt1QpKRETKZ+Vex25mfYDfAT8E\n9gKvAVe4+zvVC09EREp1eAXbjgZ2uvvvAcxsJTAJKJjYW1pavH///hXsUkSk+XR1df3R3Y9NWr+S\nxD4I2BN7vRf4u29XMrM2oA2gX79+tLW1VbBLEZHmM2fOnN2l1K/5yVN373D3VndvbWlpqfXuRESa\nXiWJ/UPgxNjrweEyERFpoEoS+2vAMDM7xcyOAC4HOqsTloiIlKvsMXZ3/9LM/gl4BugDLHH3t0t9\nn1dffbXcEJrW6NGj8y7XZ1m6fJ+lPsfS6W+yegp9lqWo5OQp7v408HTFUYiISNXozlMRkYxRYhcR\nyRgldhGRjFFiFxHJGCV2EZGMUWIXEckYJXYRkYyp6Dp2aV5PP1357Qu7d389r9ENN9xQ8fuJSEA9\ndhGRjFGPXUpSjZ56zpAhQ6LyyJEjAdi6dWvV3r9ZnHPOOVG5vf3rB5l1d3cDMGnSpLrH1JsMGDAA\ngOXLlxetO2vWLAC2bNlS05hqTT12EZGMUWIXEckYDcVIUdUcfilk3rx5AEycOLHm+8qaQkMt27Zt\nq3MkvdOIESMS180NxUyZMqVW4dSFeuwiIhmjxC4ikjEaipG8LrnkksR1Z8+eHZV37doVlT/++GMA\n4s+6Xb16dRWik7jTTz897/KZM2fWOZLeY+jQoVF5xowZDYykMdRjFxHJGCV2EZGMycRQzPz586Py\nGWec0WPdxx57LCrv2LEDgJdeeqk2gaVYoa/3OdOnT4/K7777bo91kwy/PPnkk8kCEwAmTJjQ6BB6\nnc7Ozqh8+OHlpbajjjoKgHXr1kXL1q9fH5UXLVpUZnT1VbTHbmZLzGy/mW2LLRtgZs+a2Xvh72Nq\nG6aIiCSV5L+1h4AHgGWxZe3ARnefb2bt4eufVz+8ZIr10uMuvfTSGkZS2JIlS6JyGk4g3nHHHVF5\n1KhRUfnAgQMA7Nmzp+4xydfOPffcvMufeOKJOkfSe5TbS8+nb9++UXny5MlR+ZNPPonKa9asqdr+\nqq1oj93dXwQ++dbiScDSsLwUuKjKcYmISJnKPXk60N27wvI+YGChimbWZmabzWzzwYMHy9ydiIgk\nVfF3F3d3M/Me1ncAHQAnnHBCwXqV2LBhQ1TOnVTatGlTtGz8+PG12G1JrrvuuqichqGYuHJnuitl\nKoIVK1aUtY9mVWj4MW1/W5Wqx3QXcVOnTo3KqR6KKeAjMzseIPy9v3ohiYhIJcpN7J3ANWH5GmBd\nD3VFRKSOig7FmNkKYBzwPTPbC/wLMB9YZWZTgd3AZbUMspj7778/bzlnwYIFebcbPHgw8M3Z8eJf\nZS+7rOdmffbZZ1H5xRdfjMoPPPDAIXWb5fxCKbexx6/g+PTTT2sRTua0trb2uD5+1UaWtbW1Ve29\nXn755ai8b98+4JtXwhSyatUqoHieaISiid3dryiw6vwqxyIiIlWgKQVERDImE1MKlGvv3r0APPjg\ng3nX5xvWKeTOO+/scf3NN9+cPLAUO+ussxLX7ejoqGEk2VTNIYi0iQ9DXXRRZbfOXHnllVE53zDg\n66+/HpXnzp2b9z2OPvpo4JtX5sQf0PH5559XFGMl1GMXEcmYpu6xV+rUU0+NymeeeeYh6998882o\nnOVb8Eu5lvjqq6+uYSTZlzvhHxc/+ZdluQm6SnXjjTcC8MEHHyTeJn7vRnd3d1SOTzWQz8iRI6Ny\nI4+LeuwiIhmjxC4ikjEaiqnAfffd1+P6F154oT6BNMDw4cMT143PFJl7XJ4kd9VVV/W4/t57761T\nJOkRv5+ilCGYfObMmROVC51I7W3UYxcRyRgldhGRjNFQTImuvfbaonXWrl0LwDPPPFPjaBrn7rvv\nTly3Wa7aqJX4Ndf5xKe2aGYTJ06syfsedljy/u/tt98elWsVTxLqsYuIZIwSu4hIxmgopkRJZnJ7\n+OGH6xBJY8yePTtxXd2MVDvxW96bxYwZMxqy3/jwSjHxK8AaST12EZGMUY89oX79+vW4fuXKlVG5\nkZP/1MKQIUOi8pgxYxJvp2vWy3faaaf1uL6UXqQkN3ToUAAuuOCCaFmxaQTiesu/ffXYRUQyRold\nRCRjNBST0IoVK3pcv2zZsjpFUn8LFy5MXFcnTKvjnnvuaXQITSnfYy2LWbNmTVTeunVrNcMpW9Ee\nu5mdaGabzOwdM3vbzG4Klw8ws2fN7L3w9zG1D1dERIpJMhTzJfAzdx8BjAF+amYjgHZgo7sPAzaG\nr0VEpMGSPMy6C+gKy5+Z2XZgEDAJGBdWWwq8APy8JlE2SLHrZh999NE6RdK7TZ8+PSrrShhJm1Ie\nFJPP4sWLqxRJ9ZR08tTMTgZGAq8AA8OkD7APGFhgmzYz22xmmw8ePFhBqCIikkTixG5mRwNrgGnu\n/uf4Ond3wPNt5+4d7t7q7q0tLS0VBSsiIsUluirGzPoSJPVH3P3xcPFHZna8u3eZ2fHA/loFWU/x\nm3HOPvvsHusuX7681uGkwkknnRSVS7lBY9++fYdsF3+u5XHHHZd3u9xzP0u5xbzYU+nT4qmnnmp0\nCL3Wrbfemnf5uHHjarK/Rs7eWEySq2IMWAxsd/f4XK2dwDVh+RpgXfXDExGRUiXpsZ8FXA381sze\nCJfNAOYDq8xsKrAbKD47Vi8Vv2W42DXbvWWSn95k2rRpjQ6hqPiJ7t7a05o6dWqjQ0i1WvXM0yjJ\nVTG/BqzA6vOrG46IiFRKUwqIiGSMphQAxo4dW7RO7vFuesxbOqXhnoOLL764aJ2Ojo46RNI7zZo1\nKyrPnTu3bvuND79u3769bvuthHrsIiIZo8QuIpIxTT0UM2rUKADa24tPczNv3rxah9Nrxa8iqfT2\n63LdddddUfn5559vSAy10r9//8R1u7u7axhJ77Zly5aovHbtWgAmT55c1X3k7qeYMmVKVd+33tRj\nFxHJGCV2EZGMaeqhmGJn1pcsWRKVv/rqq1qHkwq99eaeNCs2DUN8OgQJLFq06Bu/AW655ZaoPH78\n+B6337hxY1Q+7LCv+7fPPfdctUJsKPXYRUQypul67LptW3qbXI9d34Yqs2DBgrzlZqQeu4hIxiix\ni4hkTNMNxSS5bTtHj3kTkTRSj11EJGOU2EVEMqbphmKKuf7666Pynj17GhiJiEh51GMXEckYJXYR\nkYxpuqEY3QQiIllXtMduZkeZ2atm9qaZvW1mc8Llp5jZK2a208z+08yOqH24IiJSTJIe+xfAee7+\nFzPrC/zazDYA04F73H2lmf0SmAosLDWA0aNHl7qJFKDPsjr0OVaPPsvGKNpj98Bfwpd9wx8HzgNW\nh8uXAhfVJEIRESlJopOnZtbHzN4A9gPPAu8Dn7r7l2GVvcCgAtu2mdlmM9t88ODBasQsIiI9SJTY\n3f3/3P0HwGBgNDA86Q7cvcPdW929taWlpcwwRUQkqZIud3T3T4FNwFigv5nlxugHAx9WOTYRESlD\nkqtijjWz/mH5O8APge0ECf6SsNo1wLpaBSkiIsmZu/dcwewMgpOjfQj+I1jl7v9qZkOBlcAAYCtw\nlbt/UeS9DgD/C/yxCrH3Rt9DbUsjtS2dmqltQ9z92KQbF03s1WZmm929ta47rRO1LZ3UtnRS2wrT\nlAIiIhmjxC4ikjGNSOwdDdhnvaht6aS2pZPaVkDdx9hFRKS2NBQjIpIxSuwiIhlT18RuZhea2Y5w\nqt/2eu672szsRDPbZGbvhNMZ3xQuH2Bmz5rZe+HvYxodaznC+YG2mtn68HUmpmk2s/5mttrM3jWz\n7WY2NkPH7Obwb3Gbma0Ip9xO5XEzsyVmtt/MtsWW5T1OFrgvbONbZjaqcZEXV6BtC8K/ybfMbG3u\nptBw3W1h23aY2d8n2UfdEruZ9QEeBCYAI4ArzGxEvfZfA18CP3P3EcAY4Kdhe9qBje4+DNgYvk6j\nmwjuMM75N4Jpmk8F/odgmuY0+nfgv9x9OHAmQRtTf8zMbBDwz0Cru3+f4IbCy0nvcXsIuPBbywod\npwnAsPCnjTKmD6+zhzi0bc8C33f3M4DfAbcBhDnlcuBvw21+EebSHtWzxz4a2Onuv3f3vxLctTqp\njvuvKnfvcvctYfkzggQxiKBNS8NqqZzO2MwGA/8A/Cp8bWRgmmYz6wecAywGcPe/hvMfpf6YhQ4H\nvhPO4dQCdJHS4+buLwKffGtxoeM0CVgWTjH+G4J5rI6vT6Sly9c2d//v2Gy5vyGYfwuCtq109y/c\nfRewkyCX9qieiX0QsCf2uuBUv2ljZicDI4FXgIHu3hWu2gcMbFBYlbgXuBX4Knz9NyScprmXOwU4\nAPxHOMz0KzP7Lhk4Zu7+IXAX8AeChP4n4HWycdxyCh2nrOWW64ANYbmstunkaYXM7GhgDTDN3f8c\nX+fBtaSpup7UzH4E7Hf31xsdSw0cDowCFrr7SIJ5i74x7JLGYwYQjjdPIvjP6wTguxz6dT8z0nqc\nijGzmQTDvI9U8j71TOwfAifGXqd+qt/wUYFrgEfc/fFw8Ue5r4Hh7/2Niq9MZwE/NrMPCIbLziMY\nl87CNM17gb3u/kr4ejVBok/7MQO4ANjl7gfcvRt4nOBYZuG45RQ6TpnILWZ2LfAj4Cf+9Q1GZbWt\nnon9NWBYeJb+CIITAp113H9VhePOi4Ht7n53bFUnwTTGkMLpjN39Nncf7O4nExyj5939J2RgmmZ3\n3wfsMbPTwkXnA++Q8mMW+gMwxsxawr/NXNtSf9xiCh2nTuAfw6tjxgB/ig3ZpIKZXUgw/Pljd48/\naq4TuNzMjjSzUwhOEL9a9A3dvW4/wESCM77vAzPrue8atOVsgq+CbwFvhD8TCcajNwLvAc8BAxod\nawVtHAesD8tDwz+oncBjwJGNjq/MNv0A2BwetyeAY7JyzIA5wLvANuBh4Mi0HjdgBcG5gm6Cb1pT\nCx0nwAiuuHsf+C3BlUENb0OJbdtJMJaeyyW/jNWfGbZtBzAhyT40pYCISMbo5KmISMYosYuIZIwS\nu4hIxiixi4hkjBK7iEjGKLGLiGSMEruISMb8P7ogFLmzPXQzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:      7     2     1     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8DMyi8-Y4nB",
        "colab_type": "text"
      },
      "source": [
        "# Load the learned CNN parameters. This is required when you have trained the CNN and do no want to train it again by loading the learned parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTELpZUNy5yV",
        "colab_type": "code",
        "outputId": "9bd10573-26d0-492c-9a0b-edd7c4231b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL7bMIiyZeFr",
        "colab_type": "text"
      },
      "source": [
        "# Get the predictions for the first 4 images in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQeFNxLTzBxN",
        "colab_type": "code",
        "outputId": "8f02f942-0b8f-4275-d512-ac6a3b252a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  outputs = net(images.to(device))\n",
        "  _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:      7     2     1     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r7FPw9MZoMB",
        "colab_type": "text"
      },
      "source": [
        "# Infer on the whole test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F246Hc0QzLLV",
        "colab_type": "code",
        "outputId": "20088d32-8d83-47cf-d23c-377b2c8836a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
        "                                         shuffle=False, num_workers=1)\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images.to(device))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %.3F %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 98.430 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOZILCzoZyQC",
        "colab_type": "text"
      },
      "source": [
        "# check the GPU device assigned by Google."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYHUVXeezVx2",
        "colab_type": "code",
        "outputId": "db681901-8ab4-4376-ce4a-7449b1ab6a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "import subprocess\n",
        "print(subprocess.getoutput('nvidia-smi'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Nov 15 19:46:41 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    63W / 149W |    541MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}